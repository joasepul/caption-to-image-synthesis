{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, merge, Concatenate, Dense, Dropout, Conv2D, Add, Dot, Lambda, Conv2DTranspose, Dot, Activation, Reshape, BatchNormalization, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Multiply, LeakyReLU, Flatten, MaxPool2D \n",
    "from keras.layers.convolutional import Convolution2D, UpSampling2D\n",
    "from keras.layers import PReLU, LeakyReLU\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(input_shape, name='encoder', encode_channels=[8,16, 32, 64]):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    \n",
    "    for index, channel in enumerate(encode_channels):\n",
    "        \n",
    "        shortcut = Conv2D(channel, 3, padding='same', trainable=False)(input_layer if index == 0 else encoder_block)\n",
    "        encoder_block = BatchNormalization()(input_layer if index == 0 else encoder_block)\n",
    "        encoder_block = LeakyReLU()(encoder_block)\n",
    "        encoder_block = Conv2D(channel, 3, padding='same')(encoder_block)    \n",
    "        \n",
    "        encoder_block = BatchNormalization()(encoder_block)\n",
    "        encoder_block = LeakyReLU()(encoder_block)\n",
    "        encoder_block = Conv2D(channel, 3, padding='same')(encoder_block)\n",
    "        \n",
    "        \n",
    "        encoder_block = Add()([encoder_block, shortcut])\n",
    "        \n",
    "        encoder_block = Conv2D(channel, 3, padding='same', strides=2)(encoder_block)\n",
    "        encoder_block = LeakyReLU()(encoder_block)\n",
    "        \n",
    "    \n",
    "    output_layer = encoder_block\n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "encoder = build_encoder((128,128,3), encode_channels=[16, 32])\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x, y, z = encoder.output_shape\n",
    "compression = (x*y*z)/((128**2)*3) * 128\n",
    "print(f'Encoder reduces dimensionality to {compression}% of original size.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(input_shape, name='decoder', decode_channels = [64, 32, 16, 8], use_upsampling=False):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    \n",
    "    for index, channel in enumerate(decode_channels):\n",
    "        shortcut = Conv2D(channel, 3, padding='same', trainable=False)(input_layer if index == 0 else decoder_block)\n",
    "        \n",
    "        decoder_block = BatchNormalization()(input_layer if index == 0 else decoder_block)\n",
    "        decoder_block = LeakyReLU()(decoder_block)\n",
    "        decoder_block = Conv2D(channel, 3, padding='same')(decoder_block)\n",
    "        \n",
    "        decoder_block = BatchNormalization()(decoder_block)\n",
    "        decoder_block = LeakyReLU()(decoder_block)\n",
    "        decoder_block = Conv2D(channel, 3, padding='same')(decoder_block)\n",
    "        \n",
    "        decoder_block = Add()([decoder_block, shortcut])\n",
    "        \n",
    "        if use_upsampling:\n",
    "            decoder_block = UpSampling2D(interpolation='nearest')(decoder_block)\n",
    "            decoder_block = Conv2D(channel, 3, padding='same')(decoder_block)\n",
    "            \n",
    "\n",
    "        decoder_block = Conv2DTranspose(channel, 3, padding='same', strides=2)(decoder_block)\n",
    "\n",
    "\n",
    "    \n",
    "    output_layer = Conv2D(3, 3, padding='same', activation='sigmoid')(decoder_block)\n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "decoder = build_decoder((32, 32, 32), decode_channels=[32, 16], use_upsampling=False)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(encoder, decoder, name='autoencoder'):\n",
    "    input_img = Input(shape=(128,128,3))\n",
    "    latent_representation = encoder(input_img)\n",
    "    decoded_img = decoder(latent_representation)\n",
    "    autoencoder = Model(input_img, decoded_img, name=name)\n",
    "    return autoencoder\n",
    "autoencoder = build_autoencoder(encoder, decoder)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(file_path):\n",
    "    img_paths = glob.glob(file_path + '/*')\n",
    "    data = []\n",
    "    for img_path in img_paths:\n",
    "        \n",
    "        data.append(cv2.imread(img_path) / 255.0)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_loader('./cleaned-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grap only the first 1600 images\n",
    "subset_X = X[:1600] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# custom metric to avoid the binary_accuracy rounding in keras\n",
    "def image_closeness(y_pred, y_true):\n",
    "    return K.mean(1 - K.abs(y_pred - y_true), axis=-1)\n",
    "keras.metrics.image_closeness = image_closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=[image_closeness, 'accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = autoencoder.fit(subset_X, subset_X, epochs=100, batch_size=32, shuffle=True)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = []\n",
    "for i in range(1, 6):\n",
    "    history = autoencoder.fit(subset_X, subset_X, epochs=1000, batch_size=32, shuffle=True)\n",
    "    hist.append(history)\n",
    "    autoencoder.save('./autoencoder-v3-models/autoencoder-v3-' + str(i) + 'k-epochs.h5')\n",
    "    print(i, 'k epochs~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    plot_history(history)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "losses = []\n",
    "for i, history_segment in enumerate(hist):\n",
    "    \n",
    "    losses.extend(history_segment.history['loss'])\n",
    "    accs.extend(history_segment.history['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accs)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.savefig('./autoencoder-v3-models-tanh/accuracy')\n",
    "plt.show()\n",
    "plt.plot(losses)\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig('./autoencoder-v3-models-tanh/loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('./autoencoder-v3-models/autoencoder-v3-2k-epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimgs = data_loader('./testxclean/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "# figure(num=None, figsize=(10, 10), dpi=200, facecolor='w', edgecolor='k')\n",
    "def rgb_imshow(img, name):\n",
    "#     figure(num=None, dpi=200, facecolor='w', edgecolor='k')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "#     plt.title(name, loc='left')\n",
    "    plt.imshow(cv2.cvtColor((img).astype(np.float32), cv2.COLOR_BGR2RGB))\n",
    "#     plt.savefig('./testimgs/' + name + '.jpg', bbox_inches='tight')\n",
    "    \n",
    "def show_infer_image(img_index, model, imgname):\n",
    "    \n",
    "    figure(num=None, dpi=300, facecolor='w', edgecolor='k')\n",
    "\n",
    "    img_input = testimgs[0] \n",
    "    scaled_img = cv2.resize((img_input*255).astype(np.uint8), (86,86))\n",
    "    decoded_img = model.predict(np.array([img_input]), steps=None)[0]\n",
    "    ax = plt.subplot(2, 4, 1)\n",
    "    ax.set_ylabel('Input Image')\n",
    "    rgb_imshow(img_input, None)\n",
    "    ax = plt.subplot(2, 4, 5)\n",
    "    ax.set_ylabel('Decoded Image')\n",
    "    rgb_imshow(decoded_img, None)\n",
    "    \n",
    "    img_input = testimgs[1] \n",
    "    scaled_img = cv2.resize((img_input*255).astype(np.uint8), (86,86))\n",
    "    decoded_img = model.predict(np.array([img_input]), steps=None)[0]\n",
    "    plt.subplot(2, 4, 2)\n",
    "    rgb_imshow(img_input, None)\n",
    "    plt.subplot(2, 4, 6)\n",
    "    rgb_imshow(decoded_img, None)\n",
    "    \n",
    "    img_input = testimgs[2] \n",
    "    scaled_img = cv2.resize((img_input*255).astype(np.uint8), (86,86))\n",
    "    decoded_img = model.predict(np.array([img_input]), steps=None)[0]\n",
    "    plt.subplot(2, 4, 3)\n",
    "    rgb_imshow(img_input, None)\n",
    "    plt.subplot(2, 4, 7)\n",
    "    rgb_imshow(decoded_img, None)\n",
    "    \n",
    "    img_input = testimgs[3] \n",
    "    scaled_img = cv2.resize((img_input*255).astype(np.uint8), (86,86))\n",
    "    decoded_img = model.predict(np.array([img_input]), steps=None)[0]\n",
    "    plt.subplot(2, 4, 4)\n",
    "    rgb_imshow(img_input, None)\n",
    "    plt.subplot(2, 4, 8)\n",
    "    rgb_imshow(decoded_img, None)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./autoencoder-v3-models/results.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# for i in range(0, 4):\n",
    "#     rgb_imshow(testimgs[i], 'Input Image')\n",
    "show_infer_image(i, autoencoder, 'Residual Decoded')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
