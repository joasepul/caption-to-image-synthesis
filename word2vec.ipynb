{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df = pd.read_csv('./coco-captions-2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "  \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "  \n",
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_list = annot_df.values\n",
    "data = [] \n",
    "data_set = set()\n",
    "\n",
    "# iterate through each caption \n",
    "for row in annot_list: \n",
    "    temp = [] \n",
    "      \n",
    "    # tokenize the captions into words \n",
    "    for j in word_tokenize(row[1]): \n",
    "        data_set.add(j.lower())\n",
    "        temp.append(j.lower()) \n",
    "  \n",
    "    data.append(temp) \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'brave' in data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(data, size=100, workers=4, max_vocab_size=None, min_count = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chandelier', 0.7942395210266113),\n",
       " ('aquariums', 0.7931094169616699),\n",
       " ('valley', 0.7802001237869263),\n",
       " ('neath', 0.7800871133804321),\n",
       " ('drum', 0.7732276916503906),\n",
       " ('stairway', 0.7671425342559814),\n",
       " ('chimney', 0.7635893821716309),\n",
       " ('seravel', 0.7623745203018188),\n",
       " ('crane', 0.7557861804962158),\n",
       " ('rises', 0.7513242959976196)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('moon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save('./text_encoding.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_cleaned = []\n",
    "for row in data:\n",
    "    if len(' '.split(row)) > 20:\n",
    "        continue\n",
    "    data_cleaned.append(row.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_tags = []\n",
    "# for i in range(len(data_cleaned)):\n",
    "#     doc_tags.append(i)\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "docs = [TaggedDocument(words=word_tokenize(_d), tags=[str(i)]) for i, _d in enumerate(data_cleaned)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words model\n",
    "# model1 = gensim.models.Word2Vec(data, min_count = 1,  \n",
    "                             # size = 100, window = 5) \n",
    "# Skip Gram model \n",
    "# model2 = gensim.models.Word2Vec(data, min_count = 1, size = 100, \n",
    "                                # window = 5, sg = 1) \n",
    "\n",
    "# model_doc_100 = gensim.models.Doc2Vec(docs, vector_size=100, workers=8, dm=1, max_vocab_size=None, dm_mean=0)\n",
    "model_doc_sum = gensim.models.Doc2Vec(docs, vector_size=256, workers=8, dm=1, max_vocab_size=None, dm_mean=0, min_count=10)\n",
    "# model_doc_500 = gensim.models.Doc2Vec(docs, vector_size=500, workers=8, dm=1, max_vocab_size=None, dm_mean=0)\n",
    "# model_doc_mean = gensim.models.Doc2Vec(docs, vector_size=256, workers=8, dm=1, max_vocab_size=None, dm_mean=1, min_count=10)\n",
    "\n",
    "# dm_mean=1 enables vector averaging versus vector summing. Further testing required.\n",
    "# model_doc = gensim.models.Doc2Vec(docs, vector_size=100, min_count=5, workers=8, dm=1, max_vocab_size=None, dm_mean=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc_sum.save('textencodingmodel.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A woman uses a paintbrush on a melting candle.\n",
      "\n",
      "\n",
      "Mean\n",
      "\n",
      "a baseball player holding a bat over his shoulder.\n",
      "0.6386563181877136\n",
      "a bag that is filled with pens and scissors\n",
      "0.634752094745636\n",
      "a small airplane flying above a snow covered mountain.\n",
      "0.6334839463233948\n",
      "a narrow kitchen with a refrigerator at the end of it.\n",
      "0.6208945512771606\n",
      "a bus with a bike attached to the front is traveling down a street.\n",
      "0.6205453276634216\n",
      "\n",
      "Sum\n",
      "\n",
      "toothbrushes are arranged in a cup on the bathroom counter.\n",
      "0.6886410713195801\n",
      "a group of birds standing around in a field. \n",
      "0.6870393753051758\n",
      "workers cleaning a large green and white boat\n",
      "0.6720724105834961\n",
      "a little girl in a pink jacket riding a horse on the beach.\n",
      "0.6626769304275513\n",
      "a pile of assorted vegetables sitting side by side.\n",
      "0.6622759103775024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('35665', 0.6886410713195801),\n",
       " ('58802', 0.6870393753051758),\n",
       " ('70641', 0.6720724105834961),\n",
       " ('75843', 0.6626769304275513),\n",
       " ('81955', 0.6622759103775024)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1= 'A woman uses a paintbrush on a melting candle.'\n",
    "teststr = word_tokenize(s1)\n",
    "\n",
    "\n",
    "teststr = [x.lower() for x in teststr]\n",
    "# infer_vector = model_doc.infer_vector(teststr, steps=20000, alpha=0.025)\n",
    "# similar_documents = model_doc.docvecs.most_similar([infer_vector], topn = 10)\n",
    "# model_doc.docvecs.similarity_unseen_docs(model_doc, \\\n",
    "#                                          ['a', 'truck', 'loaded', 'down', 'with', 'bags', 'of', 'cans', 'in', 'the', 'bed', 'of', 'the', 'truck'], \\\n",
    "#                                          ['a', 'truck', 'bed', 'loaded', 'down'], \\\n",
    "#                                          steps=100000)\n",
    "\n",
    "# model_doc.docvecs.similarity_unseen_docs(model_doc, \\\n",
    "#                                          ['fresh', 'apple', 'juice'], \\\n",
    "#                                          ['gross', 'apple', 'juice'], \\\n",
    "#                                          steps=10000)\n",
    "\n",
    "num_outputs = 5\n",
    "\n",
    "print('\\n'+s1+'\\n')\n",
    "print('\\nMean\\n')\n",
    "inf_vec = model_doc_mean.infer_vector(teststr, steps=10000)#, alpha=1, min_alpha=0.002)\n",
    "output = model_doc_mean.docvecs.most_similar([inf_vec], topn=num_outputs)\n",
    "# for doc in similar_documents:\n",
    "#     print(data_cleaned[int(doc[0])])\n",
    "\n",
    "for i in range(num_outputs):    \n",
    "    print (data_cleaned[(int(output[i][0]) + 1)])\n",
    "    print (output[i][1])\n",
    "    \n",
    "print('\\nSum\\n')\n",
    "inf_vec = model_doc_sum.infer_vector(teststr, steps=10000)#, alpha=1, min_alpha=0.002)\n",
    "output = model_doc_sum.docvecs.most_similar([inf_vec], topn=num_outputs)\n",
    "\n",
    "for i in range(num_outputs):    \n",
    "    print (data_cleaned[(int(output[i][0]) + 1)])\n",
    "    print (output[i][1])\n",
    "output    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9549301027985857"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc.docvecs.similarity_unseen_docs(model_doc, \\\n",
    "                                         ['fresh', 'apple', 'juice'], \\\n",
    "                                         ['fresh', 'apple', 'juice'], \\\n",
    "                                         steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('begin', 0.81293785572052),\n",
       " ('tag', 0.7691446542739868),\n",
       " ('runner', 0.7600712180137634),\n",
       " ('read', 0.7600324153900146),\n",
       " ('student', 0.7563343644142151),\n",
       " ('own', 0.7557961940765381),\n",
       " ('balance', 0.7526955604553223),\n",
       " ('she', 0.7499886155128479),\n",
       " ('listening', 0.7498931884765625),\n",
       " ('see', 0.7497900724411011)]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc.most_similar(['wiimote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
