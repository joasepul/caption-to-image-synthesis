# caption-to-image-synthesis

This repository contains a combined model for general caption to image synthesis using the Common Objects in Context (COCO) dataset. This work explores the performance of several components of the model individually, as well as in tandem. This includes a novel autoencoder with residual blocks, several methods of word embeddings, and briefly touching on adversarial training. This repository continue to be expanded with work on generative adversarial models toward the same goal.

### Prerequisites

* Python 3.7
* Keras 2.2.4, to be converted to 2.3.0
* COCO training dataset 2017

## Authors

* **Jose Sepulveda** - [joasepul](https://github.com/joasepul)

* **Kevin Woodward** - [kevinwoodward](https://github.com/kevinwoodward)