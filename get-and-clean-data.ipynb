{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '/coco2017/' for use on Nautilus\n",
    "# './'for local use\n",
    "path_prefix = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this selects the first 1975 images, change the regex if you want more\n",
    "img_paths = glob.glob(path_prefix + 'train2017/*.jpg')\n",
    "training_imgs_num = len(img_paths)\n",
    "print(f'loaded a total of {training_imgs_num} imgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Cleaning and saving {training_imgs_num} imgs to /coco2017/cleaned-data')\n",
    "os.mkdir(path_prefix + 'cleaned-data') if not os.path.exists(path_prefix + 'cleaned-data') else None\n",
    "\n",
    "for img_path in img_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    y,x,_ = img.shape #(y, x) not (x, y)\n",
    "    \n",
    "    margin = abs(y-x)/2\n",
    "    if x > y:        \n",
    "        # Image is tall\n",
    "        img = img[:,int(math.floor(margin)):int(math.floor(x-margin))]\n",
    "    elif y > x:\n",
    "        # Image is wide\n",
    "        img = img[int(math.floor(margin)):int(math.floor(y-margin)),:]\n",
    "\n",
    "    if (img.shape[0] != img.shape[1]):\n",
    "        print('Dim mismatch')\n",
    "        \n",
    "    img = cv2.resize(img, (128,128))\n",
    "    cv2.imwrite(os.path.join(path_prefix + 'cleaned-data', img_path.split('/')[-1]), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_mapping = {}\n",
    "\n",
    "# numeric_mapping = { 'person' : 1, 'vehicle' : 2, 'outdoor' : 3, 'animal' : 4, 'accessory' : 5, 'sports' : 6, \\\n",
    "# 'kitchen' : 7, 'food' : 8, 'furniture' : 9, 'electronic' : 10, 'appliance' : 11, 'indoor' : 12 }\n",
    "\n",
    "# for dic in instances_df.categories:\n",
    "#     category_mapping[dic['id']] = numeric_mapping[dic['supercategory']]\n",
    "\n",
    "# def getSuperCat(cat):\n",
    "#     return category_mapping[cat]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihot_encode(data, num_classes=12, clip=False):\n",
    "    mhe, _ = np.histogram(data,bins=num_classes,range=(0,num_classes-1))\n",
    "    if clip:\n",
    "        return np.clip(mhe,0,1)\n",
    "    \n",
    "    mhe = [x/sum(mhe) if sum(mhe) > 0 else x/1.0 for x in mhe]\n",
    "    return mhe\n",
    "\n",
    "def embed_caption(caption):\n",
    "    caption_conv = []\n",
    "    for word in word_tokenize(caption.lower()):\n",
    "        caption_conv.append(w2v_model[word])\n",
    "    return np.array(caption_conv).tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['caption', 'id', 'image_id'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woodw\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['caption', 'id', 'image_id', 'embedded_caption'], dtype='object')\n",
      "Index(['caption', 'id', 'image_id', 'embedded_caption', 'file_name'], dtype='object')\n",
      "Index(['caption', 'categories', 'id', 'image_id', 'embedded_caption',\n",
      "       'file_name'],\n",
      "      dtype='object')\n",
      "Index(['caption', 'categories', 'super_categories', 'id', 'image_id',\n",
      "       'embedded_caption', 'file_name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_caption(cap):\n",
    "    return ' '.join(word_tokenize(cap))\n",
    "\n",
    "def get_file_name(image_id):\n",
    "    return str(image_id).rjust(12, '0') + '.jpg'\n",
    "    \n",
    "\n",
    "annot_df = None\n",
    "image_df = None\n",
    "with open(path_prefix + 'annots/annotations/captions_train2017.json') as annot_file:\n",
    "    captions_df = pd.read_json(annot_file, typ='series')\n",
    "    annot_df = pd.DataFrame(data=captions_df['annotations'])\n",
    "    annot_df = annot_df.astype({'image_id': 'int32'})\n",
    "    image_df = pd.DataFrame(data= captions_df['images'])\n",
    "    image_df = image_df.astype({'id': 'int32'}) # annot_df image_id matches image_df id\n",
    "    annot_df.sort_values(by=['image_id'], axis=0, inplace=True)\n",
    "    image_df.sort_values(by=['id'], axis=0, inplace=True)\n",
    "    annot_df['caption'] = annot_df['caption'].apply(clean_caption)\n",
    "    \n",
    "    # Embed the captions and insert as another column\n",
    "    w2v_model = Word2Vec.load(path_prefix + 'resources/text_encoding_full.bin')\n",
    "    print(annot_df.columns)\n",
    "    annot_df.insert(len(annot_df.columns), 'embedded_caption', list(map(embed_caption, list(annot_df['caption'].values))))\n",
    "    print(annot_df.columns)\n",
    "\n",
    "    # Aggregate all captions per image into one row\n",
    "#     annot_df = annot_df.groupby(['image_id', 'id', 'embedded_caption'])['caption'].agg('|'.join)\n",
    "#     print(annot_df.columns)\n",
    "    \n",
    "    # Insert file names\n",
    "#     annot_df.insert(len(annot_df.columns), 'file_name', image_df['file_name'].values)\n",
    "    annot_df['file_name'] = annot_df['image_id'].apply(get_file_name)\n",
    "        \n",
    "    print(annot_df.columns)\n",
    "    \n",
    "    # Insert class and superclass data\n",
    "    with open(path_prefix + 'annots/annotations/instances_train2017.json') as instance_file:\n",
    "        instances_df = pd.read_json(instance_file, typ='series')\n",
    "        \n",
    "        category_mapping = {}\n",
    "\n",
    "        numeric_mapping = { 'person' : 1, 'vehicle' : 2, 'outdoor' : 3, 'animal' : 4, 'accessory' : 5, 'sports' : 6, \\\n",
    "        'kitchen' : 7, 'food' : 8, 'furniture' : 9, 'electronic' : 10, 'appliance' : 11, 'indoor' : 12 }\n",
    "\n",
    "        for dic in instances_df.categories:\n",
    "            category_mapping[dic['id']] = numeric_mapping[dic['supercategory']]\n",
    "        \n",
    "        image_cats = {i : [] for i in list(annot_df.index)}\n",
    "        image_supercats = {i : [] for i in list(annot_df.index)}\n",
    "        \n",
    "        for row in instances_df.annotations:\n",
    "            image_cats[row['image_id']].append(row['category_id'])\n",
    "            image_supercats[row['image_id']].append(category_mapping[row['category_id']])\n",
    "        \n",
    "        annot_df.insert(1, 'categories', image_cats.values())\n",
    "        print(annot_df.columns)\n",
    "        annot_df.insert(2, 'super_categories', list(map(multihot_encode, list(image_supercats.values()))))\n",
    "        print(annot_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df.to_csv(path_prefix + 'resources/coco-captions-with-categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2961394626"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(annot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
